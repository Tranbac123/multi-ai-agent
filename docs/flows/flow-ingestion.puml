@startuml Flow-Ingestion
title Document Ingestion and Semantic Search Flow

participant "User" as User
participant "Web Frontend\n:3000" as WebFrontend
participant "API Gateway\n:8000" as APIGateway
participant "Ingestion Service\n:8004" as IngestionService
participant "Retrieval Service\n:8081" as RetrievalService
participant "Vector Database\n(Embeddings)" as VectorDB
participant "PostgreSQL\n:5432" as Postgres
participant "Redis\n:6379" as Redis
participant "NATS\n:4222" as NATS
participant "Audit Log\n:8096" as AuditLog
participant "Usage Metering\n:8095" as UsageMetering

== Document Upload and Processing ==
User -> WebFrontend : 1. Upload document (PDF, DOCX, TXT)\nSelect file: "company_handbook.pdf"
WebFrontend -> APIGateway : 2. POST /documents/upload\nHeaders: Content-Type: multipart/form-data, X-Tenant-Id: tenant_123\nBody: {file: "company_handbook.pdf", metadata: {title: "Company Handbook", category: "HR"}}

APIGateway -> Redis : 3. GET tenant:tenant_123\nValidate tenant permissions
Redis --> APIGateway : Tenant config with upload limits

APIGateway -> AuditLog : 4. POST /audit\nBody: {action: "document_upload", tenant_id: "tenant_123", file_name: "company_handbook.pdf", size: 2048000}
AuditLog -> Postgres : 5. INSERT INTO audit_events\nLog upload event

APIGateway -> IngestionService : 6. POST /documents/upload\nHeaders: X-Request-Id: req_789, X-Tenant-Id: tenant_123\nBody: {file: binary_data, metadata: {title: "Company Handbook", category: "HR"}}

== Document Processing ==
IngestionService -> IngestionService : 7. Extract text from PDF\nPII detection and redaction\nChunking strategy (512 tokens)

IngestionService -> VectorDB : 8. Generate embeddings\nPOST /embeddings\nBody: {text_chunks: ["chunk1", "chunk2", ...], model: "text-embedding-ada-002"}
VectorDB --> IngestionService : 200 OK\n{embeddings: [[0.1, 0.2, ...], [0.3, 0.4, ...], ...]}

IngestionService -> Postgres : 9. INSERT INTO documents\nBody: {tenant_id: "tenant_123", title: "Company Handbook", file_path: "/uploads/doc_456.pdf", status: "processing"}
IngestionService -> Postgres : 10. INSERT INTO document_chunks\nBody: {document_id: "doc_456", chunk_index: 0, content: "chunk1", embedding_id: "emb_001"}

IngestionService -> VectorDB : 11. POST /index\nBody: {tenant_id: "tenant_123", document_id: "doc_456", chunks: [{id: "chunk_001", embedding: [0.1, 0.2, ...], metadata: {...}}]}
VectorDB --> IngestionService : 200 OK\n{indexed: true, chunks_count: 15}

IngestionService -> Postgres : 12. UPDATE documents\nSET status = 'indexed', chunks_count = 15\nWHERE id = 'doc_456'

== Event Publishing ==
IngestionService -> NATS : 13. PUBLISH tenant.ingestion.document_indexed\n{tenant_id: "tenant_123", document_id: "doc_456", chunks_count: 15, timestamp: "..."}

IngestionService -> UsageMetering : 14. POST /usage\nBody: {service: "ingestion", tenant_id: "tenant_123", action: "document_upload", tokens_used: 5120, cost: 0.01}
UsageMetering -> Postgres : 15. INSERT INTO usage_log\nTrack processing costs

IngestionService --> APIGateway : 16. 200 OK\n{document_id: "doc_456", status: "indexed", chunks_count: 15, processing_time_ms: 2500}

APIGateway --> WebFrontend : 17. 200 OK\n{success: true, document_id: "doc_456", message: "Document successfully indexed"}

== Semantic Search After Indexing ==
User -> WebFrontend : 18. Search: "What are the vacation policies?"
WebFrontend -> APIGateway : 19. POST /search/semantic\nHeaders: X-Tenant-Id: tenant_123\nBody: {query: "What are the vacation policies?", filters: {category: "HR"}}

APIGateway -> RetrievalService : 20. POST /search\nHeaders: X-Tenant-Id: tenant_123\nBody: {query: "What are the vacation policies?", limit: 5}

RetrievalService -> VectorDB : 21. POST /search\nBody: {query: "What are the vacation policies?", tenant_id: "tenant_123", limit: 5, similarity_threshold: 0.8}
VectorDB --> RetrievalService : 200 OK\n{results: [{chunk_id: "chunk_023", similarity: 0.92, content: "Vacation policies: Employees are entitled to..."}, ...]}

RetrievalService -> Postgres : 22. SELECT * FROM document_chunks\nWHERE id IN ('chunk_023', 'chunk_045', ...)
Postgres --> RetrievalService : Chunk data with metadata

RetrievalService --> APIGateway : 23. 200 OK\n{results: [{content: "Vacation policies: Employees are entitled to 20 days annual leave...", document: "Company Handbook", page: 45}, ...], total_results: 3}

APIGateway -> UsageMetering : 24. POST /usage\nBody: {service: "retrieval", tenant_id: "tenant_123", action: "semantic_search", queries_count: 1}
APIGateway -> AuditLog : 25. POST /audit\nBody: {action: "semantic_search", tenant_id: "tenant_123", query: "What are the vacation policies?", results_count: 3}

APIGateway --> WebFrontend : 26. 200 OK\n{results: [{content: "Vacation policies...", source: "Company Handbook", page: 45, relevance: 0.92}, ...]}

== Error Handling ==
alt Document processing fails
    IngestionService --> APIGateway : 500 Error\n{error: "Text extraction failed", document_id: "doc_456"}
    APIGateway -> Postgres : 27. UPDATE documents\nSET status = 'failed', error_message = 'Text extraction failed'\nWHERE id = 'doc_456'
    APIGateway --> WebFrontend : 500 Error\n{error: "Document processing failed", retry_after: 60}
end

alt Vector indexing fails
    VectorDB --> IngestionService : 500 Error\n{error: "Indexing service unavailable"}
    IngestionService -> Redis : 28. SET failed_indexing:doc_456\nQueue for retry
    IngestionService -> NATS : 29. PUBLISH tenant.ingestion.retry_required\n{document_id: "doc_456", retry_count: 1}
    note right of IngestionService : Implement exponential backoff\nDead letter queue for persistent failures
end

alt Search timeout
    RetrievalService --> APIGateway : 504 Gateway Timeout\n{error: "Vector search timeout"}
    APIGateway --> WebFrontend : 504 Error\n{error: "Search temporarily unavailable", retry_after: 30}
end

== Background Processing ==
note over IngestionService, Postgres : Background: Document cleanup\nEmbedding optimization\nIndex maintenance\nUsage analytics aggregation\nCompliance reporting

@enduml

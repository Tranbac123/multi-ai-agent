@startuml Flow-Retrieval
title Complex Retrieval Flow with Router Intelligence

participant "User" as User
participant "AI Chatbot UI\n:3001" as ChatbotUI
participant "API Gateway\n:8000" as APIGateway
participant "Router Service\n:8083" as RouterService
participant "Retrieval Service\n:8081" as RetrievalService
participant "Model Gateway\n:8080" as ModelGateway
participant "Realtime Gateway\n:8084" as RealtimeGateway
participant "Vector Database\n(Embeddings)" as VectorDB
participant "PostgreSQL\n:5432" as Postgres
participant "Redis\n:6379" as Redis
participant "NATS\n:4222" as NATS
participant "Usage Metering\n:8095" as UsageMetering
participant "Audit Log\n:8096" as AuditLog

== Multi-Step Retrieval with Router Intelligence ==
User -> ChatbotUI : 1. Complex query: "Find all documents about Q4 financial performance and summarize the key metrics"
ChatbotUI -> APIGateway : 2. POST /ask\nHeaders: X-Tenant-Id: tenant_456\nBody: {query: "Find all documents about Q4 financial performance and summarize the key metrics", session_id: "sess_789"}

APIGateway -> Redis : 3. GET session:sess_789\nRetrieve conversation context
Redis --> APIGateway : Previous messages and context

== Router Service - Intelligent Tier Selection ==
APIGateway -> RouterService : 4. POST /route\nHeaders: X-Request-Id: req_101, X-Tenant-Id: tenant_456\nBody: {query: "Find all documents about Q4 financial performance and summarize the key metrics", context: {...}}

RouterService -> RouterService : 5. Feature extraction:\n- Token count: 15\n- Domain: financial\n- Complexity: high\n- Historical success rate: 0.85
RouterService -> Redis : 6. GET router:features:tenant_456\nRetrieve feature store data
Redis --> RouterService : Feature store cache

RouterService -> RouterService : 7. Classification decision:\n- Tier: advanced\n- Confidence: 0.92\n- Route to: orchestrator + retrieval
RouterService -> Postgres : 8. INSERT INTO router_decisions\nLog routing decision for analytics

RouterService --> APIGateway : 9. 200 OK\n{tier: "advanced", route_to: ["orchestrator", "retrieval"], confidence: 0.92, estimated_tokens: 800}

== Orchestrator - Multi-Step Workflow ==
APIGateway -> RetrievalService : 10. POST /search\nHeaders: X-Tenant-Id: tenant_456, X-Step-Id: step_001\nBody: {query: "Q4 financial performance", filters: {document_types: ["reports", "presentations"]}, limit: 10}

RetrievalService -> VectorDB : 11. POST /search\nBody: {query: "Q4 financial performance", tenant_id: "tenant_456", filters: {document_types: ["reports", "presentations"]}, limit: 10, similarity_threshold: 0.75}
VectorDB --> RetrievalService : 200 OK\n{results: [{chunk_id: "chunk_001", similarity: 0.89, content: "Q4 revenue increased 15% to $2.3M...", document: "Q4_Financial_Report.pdf", page: 3}, ...]}

RetrievalService -> Postgres : 12. SELECT * FROM document_chunks\nWHERE id IN ('chunk_001', 'chunk_002', ...)\nAND tenant_id = 'tenant_456'
Postgres --> RetrievalService : Chunk data with metadata

RetrievalService -> Redis : 13. SET retrieval:cache:tenant_456:q4_financial\nCache search results for 1 hour
RetrievalService --> APIGateway : 14. 200 OK\n{results: [{content: "Q4 revenue increased 15% to $2.3M...", source: "Q4_Financial_Report.pdf", page: 3, relevance: 0.89}, ...], total_results: 8}

== Model Gateway - AI Processing with Retrieved Context ==
APIGateway -> ModelGateway : 15. POST /v1/chat\nHeaders: Authorization: Bearer sk-xxx\nBody: {messages: [{role: "system", content: "You are a financial analyst. Use the provided documents to answer questions about Q4 performance."}, {role: "user", content: "Find all documents about Q4 financial performance and summarize the key metrics. Context: [retrieved documents...]"}]}

ModelGateway -> ModelGateway : 16. Token counting and cost estimation\nInput: 1200 tokens, Output: ~400 tokens\nTotal cost: $0.024

ModelGateway -> ModelGateway : 17. LLM processing with retrieved context\nGenerate comprehensive summary with citations
ModelGateway --> APIGateway : 18. 200 OK\n{content: "Based on the Q4 financial documents, here are the key metrics: Revenue increased 15% to $2.3M, Net profit margin improved to 12%, Operating expenses decreased 8%...", usage: {input_tokens: 1200, output_tokens: 380, total_cost: 0.024}}

== Real-time Streaming Response ==
APIGateway -> RealtimeGateway : 19. WebSocket /ws/tenant_456\nStream response to user
RealtimeGateway -> NATS : 20. SUBSCRIBE tenant.tenant_456.realtime\nListen for streaming events

APIGateway -> NATS : 21. PUBLISH tenant.tenant_456.realtime\n{type: "response_chunk", content: "Based on the Q4 financial documents...", session_id: "sess_789"}

== Usage Tracking and Analytics ==
APIGateway -> UsageMetering : 22. POST /usage\nHeaders: X-Tenant-Id: tenant_456\nBody: {service: "retrieval", action: "semantic_search", queries_count: 1, documents_retrieved: 8, tokens_used: 1200, cost: 0.024}
UsageMetering -> Postgres : 23. INSERT INTO usage_log\nTrack retrieval and AI usage costs

APIGateway -> AuditLog : 24. POST /audit\nHeaders: X-Tenant-Id: tenant_456\nBody: {action: "complex_query", user_id: "user_123", query_type: "financial_analysis", documents_accessed: 8, success: true}
AuditLog -> Postgres : 25. INSERT INTO audit_events\nLog complex query execution

== Event Publishing ==
APIGateway -> NATS : 26. PUBLISH tenant.usage.retrieval\n{tenant_id: "tenant_456", service: "retrieval", documents_retrieved: 8, tokens_used: 1200}
APIGateway -> NATS : 27. PUBLISH tenant.analytics.query_complexity\n{tenant_id: "tenant_456", complexity: "high", success_rate: 1.0, response_time_ms: 2500}

== Final Response ==
APIGateway --> ChatbotUI : 28. 200 OK\n{answer: "Based on the Q4 financial documents, here are the key metrics: Revenue increased 15% to $2.3M, Net profit margin improved to 12%, Operating expenses decreased 8%...", citations: ["[1] Q4_Financial_Report.pdf, page 3", "[2] Q4_Executive_Summary.pdf, page 1"], trace: ["Router: advanced tier selected", "Retrieval: 8 documents found", "AI: comprehensive analysis generated"]}

RealtimeGateway --> ChatbotUI : 29. WebSocket message\n{type: "response_complete", session_id: "sess_789", total_chunks: 3}

== Error Handling and Fallbacks ==
alt Router service unavailable
    RouterService --> APIGateway : 503 Service Unavailable\n{error: "Router service down"}
    APIGateway -> RetrievalService : Direct retrieval (fallback)\nSkip intelligent routing
    note right of APIGateway : Use default retrieval strategy\nLog service degradation
end

alt Vector search timeout
    VectorDB --> RetrievalService : 504 Gateway Timeout\n{error: "Vector search timeout"}
    RetrievalService -> Postgres : 30. SELECT * FROM document_chunks\nFallback to keyword search
    Postgres --> RetrievalService : Keyword search results
    note right of RetrievalService : Graceful degradation\nUse traditional search as fallback
end

alt Model gateway error
    ModelGateway --> APIGateway : 500 Error\n{error: "OpenAI API rate limit exceeded"}
    APIGateway -> Redis : 31. SET retry:model_gateway:req_101\nQueue for retry with backoff
    APIGateway --> ChatbotUI : 503 Error\n{error: "AI service temporarily unavailable", retry_after: 60}
end

== Advanced Features ==
note over RetrievalService, VectorDB : Advanced Retrieval Features
RetrievalService -> RetrievalService : 32. Hybrid search:\n- Vector similarity: 0.89\n- Keyword matching: 0.92\n- Metadata filtering: 0.95\n- Combined score: 0.91

RetrievalService -> RetrievalService : 33. Reranking with ML model:\n- Document relevance: 0.89\n- Content quality: 0.85\n- Freshness: 0.92\n- Final rank: 1

== Background Optimization ==
note over RetrievalService, Postgres : Background: Query optimization\nIndex maintenance\nCache warming\nPerformance analytics\nCost optimization

@enduml

sequenceDiagram
    participant ğŸ‘¤ as ğŸ‘¤ User
    participant ğŸ¤– as ğŸ¤– AI Chatbot UI<br/>:3001
    participant ğŸšª as ğŸšª API Gateway<br/>:8000
    participant ğŸ¯ as ğŸ¯ Router Service<br/>:8083
    participant ğŸ¼ as ğŸ¼ Orchestrator<br/>:8081
    participant ğŸ› ï¸ as ğŸ› ï¸ Tools Service<br/>:8082
    participant ğŸ•·ï¸ as ğŸ•·ï¸ FIRECRAWL API
    participant ğŸ¤– as ğŸ¤– Model Gateway<br/>:8080
    participant ğŸ§  as ğŸ§  OpenAI API
    participant ğŸ“š as ğŸ“š Retrieval Service<br/>:8081
    participant ğŸ§® as ğŸ§® Vector Database
    participant âš¡ as âš¡ Realtime Gateway<br/>:8084
    participant ğŸ“Š as ğŸ“Š Usage Metering<br/>:8095
    participant ğŸ“ as ğŸ“ Audit Log<br/>:8096
    participant ğŸ”´ as ğŸ”´ Redis<br/>:6379
    participant ğŸ˜ as ğŸ˜ PostgreSQL<br/>:5432
    participant ğŸ“¡ as ğŸ“¡ NATS<br/>:4222

    Note over ğŸ‘¤,ğŸ“¡: ğŸŒŸ Complete User Journey: From Question to AI Response with Web Search

    %% Step 1: User Interaction
    ğŸ‘¤->>ğŸ¤–: 1. ğŸ’¬ "What's the latest AI news?"
    Note over ğŸ¤–: ğŸ¨ Frontend Processing<br/>User Input Validation<br/>UI State Management

    %% Step 2: API Gateway Entry
    ğŸ¤–->>ğŸšª: 2. ğŸ“¤ POST /ask<br/>Headers: Content-Type: application/json<br/>X-Tenant-Id: tenant_123<br/>X-Session-Id: sess_456<br/>Body: {query: "What's the latest AI news?", session_id: "sess_456"}

    %% Step 3: Authentication & Validation
    Note over ğŸšª: ğŸ” Authentication Layer<br/>JWT Validation â€¢ Rate Limiting<br/>Tenant Context Injection
    ğŸšª->>ğŸ”´: 3. ğŸ” GET session:sess_456<br/>Retrieve user session context
    ğŸ”´-->>ğŸšª: âœ… Session data: {user_id: "user_123", tenant: "tenant_123", preferences: {...}}

    %% Step 4: Audit Logging
    ğŸšª->>ğŸ“: 4. ğŸ“ POST /audit<br/>Log incoming request
    ğŸ“->>ğŸ˜: 5. ğŸ’¾ INSERT INTO audit_events<br/>{action: "chat_query", user_id: "user_123", query: "What's the latest AI news?", timestamp: NOW()}
    ğŸ“-->>ğŸšª: âœ… Audit logged

    %% Step 5: Intelligent Routing
    ğŸšª->>ğŸ¯: 6. ğŸ¯ POST /route<br/>Intelligent request routing
    Note over ğŸ¯: ğŸ§  Feature Extraction<br/>- Token count: 5<br/>- Domain: technology<br/>- Complexity: medium<br/>- Historical success: 0.92
    ğŸ¯->>ğŸ”´: 7. ğŸ“Š GET router:features:tenant_123<br/>Retrieve feature store data
    ğŸ”´-->>ğŸ¯: ğŸ“ˆ Feature cache: {avg_response_time: 2.3s, success_rate: 0.95}
    ğŸ¯->>ğŸ¯: 8. ğŸ¯ Classification Decision<br/>Tier: standard<br/>Confidence: 0.89<br/>Route: orchestrator + tools
    ğŸ¯-->>ğŸšª: âœ… {tier: "standard", route_to: ["orchestrator", "tools"], confidence: 0.89}

    %% Step 6: Orchestrator Processing
    ğŸšª->>ğŸ¼: 9. ğŸ¼ POST /workflows/execute<br/>Workflow orchestration
    Note over ğŸ¼: ğŸ¼ LangGraph Workflow<br/>Multi-step Processing<br/>Tool Coordination<br/>Loop Safety (MAX_STEPS: 10)

    %% Step 7: Web Search Detection & Execution
    ğŸ¼->>ğŸ› ï¸: 10. ğŸ› ï¸ POST /v1/tools/exec<br/>Web search execution
    Note over ğŸ› ï¸: ğŸ” Web Search Detection<br/>Keywords: "latest", "news"<br/>Trigger: FIRECRAWL search
    ğŸ› ï¸->>ğŸ•·ï¸: 11. ğŸ•·ï¸ POST /v1/search<br/>Headers: Authorization: Bearer fc-xxx<br/>Body: {query: "latest AI news 2024", limit: 5}
    ğŸ•·ï¸-->>ğŸ› ï¸: âœ… {data: [{title: "GPT-4 Updates", content: "...", url: "..."}, ...]}
    ğŸ› ï¸->>ğŸ› ï¸: 12. ğŸ”„ Result Processing<br/>Combine top 3 results<br/>Extract key information<br/>Format for AI context
    ğŸ› ï¸-->>ğŸ¼: âœ… {success: true, output: "Latest AI news: GPT-4 improvements, new language models...", execution_time_ms: 1250}

    %% Step 8: Document Retrieval (if needed)
    ğŸ¼->>ğŸ“š: 13. ğŸ“š POST /search<br/>Document retrieval (optional)
    ğŸ“š->>ğŸ§®: 14. ğŸ§® POST /search<br/>Vector similarity search
    ğŸ§®-->>ğŸ“š: âœ… {results: [{chunk_id: "chunk_001", similarity: 0.87, content: "..."}, ...]}
    ğŸ“š-->>ğŸ¼: âœ… {results: [{content: "AI developments in 2024...", source: "tech_report.pdf", relevance: 0.87}, ...]}

    %% Step 9: AI Model Processing
    ğŸ¼->>ğŸ¤–: 15. ğŸ¤– POST /v1/chat<br/>AI model request
    Note over ğŸ¤–: ğŸ§  Model Gateway Processing<br/>Provider Selection â€¢ Cost Optimization<br/>Token Counting â€¢ Rate Limiting
    ğŸ¤–->>ğŸ§ : 16. ğŸ§  POST /v1/chat/completions<br/>Headers: Authorization: Bearer sk-xxx<br/>Body: {model: "gpt-4o-mini", messages: [{role: "system", content: "You have access to latest AI news: GPT-4 improvements..."}, {role: "user", content: "What's the latest AI news?"}], temperature: 0.7}
    ğŸ§ -->>ğŸ¤–: âœ… {choices: [{message: {content: "Based on the latest information, here are the key AI developments..."}}], usage: {input_tokens: 850, output_tokens: 320, total_cost: 0.018}}
    ğŸ¤–-->>ğŸ¼: âœ… {content: "Based on the latest information, here are the key AI developments: GPT-4 improvements, new language models...", usage: {tokens: 1170, cost: 0.018}}

    %% Step 10: Real-time Streaming
    ğŸšª->>âš¡: 17. âš¡ WebSocket /ws/tenant_123<br/>Real-time response streaming
    âš¡->>ğŸ“¡: 18. ğŸ“¡ SUBSCRIBE tenant.tenant_123.realtime<br/>Listen for streaming events
    ğŸšª->>ğŸ“¡: 19. ğŸ“¡ PUBLISH tenant.tenant_123.realtime<br/>{type: "response_chunk", content: "Based on the latest information...", session_id: "sess_456"}

    %% Step 11: Usage Tracking
    ğŸšª->>ğŸ“Š: 20. ğŸ“Š POST /usage<br/>Usage tracking
    Note over ğŸ“Š: ğŸ“Š Usage Metering<br/>Cost Calculation â€¢ Budget Monitoring<br/>Performance Metrics
    ğŸ“Š->>ğŸ˜: 21. ğŸ’¾ INSERT INTO usage_log<br/>{tenant_id: "tenant_123", service: "api-gateway", tokens_used: 1170, cost: 0.018, timestamp: NOW()}
    ğŸ“Š->>ğŸ”´: 22. ğŸ“ˆ INCRBY tenant:tenant_123:cost:current_month<br/>Add to monthly cost: +0.018
    ğŸ“Š->>ğŸ”´: 23. ğŸ“Š SET tenant:tenant_123:usage:api_gateway<br/>Update usage counter
    ğŸ“Š-->>ğŸšª: âœ… Usage tracked

    %% Step 12: Final Audit
    ğŸšª->>ğŸ“: 24. ğŸ“ POST /audit<br/>Final audit logging
    ğŸ“->>ğŸ˜: 25. ğŸ’¾ UPDATE audit_events<br/>SET success = true, response_time_ms = 2500<br/>WHERE request_id = 'req_789'
    ğŸ“-->>ğŸšª: âœ… Audit updated

    %% Step 13: Event Publishing
    ğŸšª->>ğŸ“¡: 26. ğŸ“¡ PUBLISH tenant.usage.api_gateway<br/>{tenant_id: "tenant_123", endpoint: "/ask", tokens: 1170, cost: 0.018, timestamp: "..."}
    ğŸšª->>ğŸ“¡: 27. ğŸ“¡ PUBLISH tenant.analytics.query_complexity<br/>{tenant_id: "tenant_123", complexity: "medium", success_rate: 1.0, response_time_ms: 2500}

    %% Step 14: Final Response
    ğŸšª-->>ğŸ¤–: 28. âœ… 200 OK<br/>{answer: "Based on the latest information, here are the key AI developments: GPT-4 improvements, new language models, enhanced reasoning capabilities...", citations: ["[1] Live web data via FIRECRAWL", "[2] Internal knowledge base"], trace: ["Web search successful", "Router: standard tier selected", "AI: comprehensive response generated"]}

    %% Step 15: Real-time Update
    âš¡-->>ğŸ¤–: 29. ğŸ“¡ WebSocket message<br/>{type: "response_complete", session_id: "sess_456", total_chunks: 2, final_tokens: 320}

    %% Step 16: User Experience
    ğŸ¤–-->>ğŸ‘¤: 30. ğŸ’¬ Display AI Response<br/>ğŸ¨ Rich UI with citations<br/>ğŸ“Š Live web data integration<br/>ğŸ”— Source links and references

    %% Error Handling Branch
    Note over ğŸ‘¤,ğŸ“¡: ğŸš¨ Error Handling Scenarios

    alt ğŸš¨ Web Search Fails
        ğŸ•·ï¸-->>ğŸ› ï¸: âŒ 500 Error: API timeout
        ğŸ› ï¸-->>ğŸ¼: âš ï¸ {success: false, output: "Web search temporarily unavailable"}
        ğŸ¼->>ğŸ¤–: ğŸ”„ Continue with AI-only response
        Note over ğŸ¼: ğŸ›¡ï¸ Graceful Degradation<br/>AI responds without live data<br/>User informed of limitation
    end

    alt ğŸš¨ AI Model Fails
        ğŸ§ -->>ğŸ¤–: âŒ 500 Error: Rate limit exceeded
        ğŸ¤–-->>ğŸ¼: âš ï¸ {error: "OpenAI API rate limit exceeded"}
        ğŸ¼-->>ğŸšª: ğŸ”„ Fallback response
        ğŸšª-->>ğŸ¤–: âš ï¸ {answer: "I apologize, but I'm having trouble connecting to the AI service right now. Please try again later.", citations: [], trace: ["AI service temporarily unavailable"]}
        ğŸ¤–-->>ğŸ‘¤: ğŸ’¬ Display error message with retry option
    end

    alt ğŸš¨ Router Service Unavailable
        ğŸ¯-->>ğŸšª: âŒ 503 Service Unavailable
        ğŸšª->>ğŸ¼: ğŸ”„ Direct routing (fallback)
        Note over ğŸšª: ğŸ›¡ï¸ Default Strategy<br/>Skip intelligent routing<br/>Log service degradation
    end

    %% Background Processing
    Note over ğŸšª,ğŸ˜: ğŸ”„ Background Processing<br/>ğŸ“Š Analytics aggregation<br/>ğŸ§¹ Session cleanup<br/>ğŸ“ˆ Performance optimization<br/>ğŸ”’ Security monitoring

name: Test Impact Selection & Flakiness Management

on:
  pull_request:
    branches: [main, develop]
  push:
    branches: [main, develop]
  schedule:
    - cron: "0 9 * * 1" # Weekly on Monday at 9 AM

jobs:
  test-impact-analysis:
    runs-on: ubuntu-latest
    outputs:
      impact-level: ${{ steps.impact.outputs.level }}
      affected-services: ${{ steps.impact.outputs.services }}
      test-selection: ${{ steps.impact.outputs.tests }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Fetch full history for git diff

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-rerunfailures pytest-asyncio

      - name: Analyze test impact
        id: impact
        run: |
          python -c "
          import sys
          import subprocess
          from pathlib import Path

          # Get changed files
          if '${{ github.event_name }}' == 'pull_request':
              base = '${{ github.event.pull_request.base.sha }}'
              head = '${{ github.event.pull_request.head.sha }}'
              result = subprocess.run(['git', 'diff', '--name-only', base, head], 
                                    capture_output=True, text=True)
          else:
              result = subprocess.run(['git', 'diff', '--name-only', 'HEAD~1'], 
                                    capture_output=True, text=True)

          changed_files = [f.strip() for f in result.stdout.split('\n') if f.strip()]

          # Analyze impact
          sys.path.append('tests/_plugins')
          from flakiness_manager import test_impact_analyzer

          impact_analysis = test_impact_analyzer.analyze_changed_files(changed_files)
          impacted_tests = test_impact_analyzer.get_impacted_tests(changed_files)

          print(f'impact-level={impact_analysis.impact_level.value}')
          print(f'affected-services={",".join(impact_analysis.affected_services)}')
          print(f'test-selection={",".join(impacted_tests[:10])}')  # Limit to first 10
          "

      - name: Generate impact report
        run: |
          echo "## Test Impact Analysis" >> $GITHUB_STEP_SUMMARY
          echo "- **Impact Level**: ${{ steps.impact.outputs.level }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Affected Services**: ${{ steps.impact.outputs.services }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Selected Tests**: ${{ steps.impact.outputs.tests }}" >> $GITHUB_STEP_SUMMARY

  flakiness-analysis:
    runs-on: ubuntu-latest
    needs: test-impact-analysis
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-rerunfailures pytest-asyncio

      - name: Run flakiness analysis
        run: |
          python -c "
          import sys
          sys.path.append('tests/_plugins')
          from flakiness_manager import flakiness_detector, flakiness_reporter

          # Generate weekly report
          report = flakiness_reporter.generate_weekly_report()

          print('## Flakiness Report')
          print(f'Total Tests: {report[\"metrics\"][\"total_tests\"]}')
          print(f'Stable Tests: {report[\"metrics\"][\"stable_tests\"]}')
          print(f'Flaky Tests: {report[\"metrics\"][\"flaky_tests\"]}')
          print(f'Quarantined Tests: {report[\"metrics\"][\"quarantined_tests\"]}')
          print(f'Flakiness Rate: {report[\"metrics\"][\"flakiness_rate\"]:.1f}%')

          if report['quarantine_list']:
              print('\\n## Quarantined Tests')
              for test in report['quarantine_list']:
                  print(f'- {test[\"test_name\"]}: {test[\"quarantine_reason\"]}')

          if report['recommendations']:
              print('\\n## Recommendations')
              for rec in report['recommendations']:
                  print(f'- {rec}')
          "

  selective-testing:
    runs-on: ubuntu-latest
    needs: test-impact-analysis
    if: always()

    strategy:
      matrix:
        test-suite:
          - unit
          - integration
          - e2e
          - performance
          - observability
          - security
          - adversarial

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-rerunfailures pytest-asyncio httpx hypothesis locust

      - name: Run selective tests
        run: |
          # Determine which test suites to run based on impact level
          IMPACT_LEVEL="${{ needs.test-impact-analysis.outputs.impact-level }}"
          AFFECTED_SERVICES="${{ needs.test-impact-analysis.outputs.affected-services }}"

          case $IMPACT_LEVEL in
            "high")
              echo "Running all test suites due to high impact"
              pytest tests/unit/ tests/integration/ tests/e2e/ -v --tb=short
              ;;
            "medium")
              echo "Running affected test suites due to medium impact"
              if [[ "$AFFECTED_SERVICES" == *"${{ matrix.test-suite }}"* ]]; then
                pytest tests/${{ matrix.test-suite }}/ -v --tb=short
              else
                echo "Skipping ${{ matrix.test-suite }} tests - not affected"
              fi
              ;;
            "low")
              echo "Running minimal tests due to low impact"
              if [[ "$AFFECTED_SERVICES" == *"${{ matrix.test-suite }}"* ]]; then
                pytest tests/${{ matrix.test-suite }}/ -v --tb=short -m "not slow"
              else
                echo "Skipping ${{ matrix.test-suite }} tests - not affected"
              fi
              ;;
            *)
              echo "Running basic smoke tests"
              pytest tests/unit/ -v --tb=short -m "smoke"
              ;;
          esac

      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results-${{ matrix.test-suite }}
          path: |
            .pytest_cache/
            test-results.xml

  flakiness-budget-check:
    runs-on: ubuntu-latest
    needs: [test-impact-analysis, flakiness-analysis]
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-rerunfailures pytest-asyncio

      - name: Check flakiness budget
        run: |
          python -c "
          import sys
          sys.path.append('tests/_plugins')
          from flakiness_manager import flakiness_detector

          # Get global flakiness metrics
          metrics = flakiness_detector.get_global_flakiness_metrics()

          # Check flakiness budget (5% max)
          flakiness_rate = metrics['flakiness_rate']
          quarantine_rate = metrics['quarantine_rate']

          print(f'Current flakiness rate: {flakiness_rate:.1f}%')
          print(f'Current quarantine rate: {quarantine_rate:.1f}%')

          # Fail if budget exceeded
          if flakiness_rate > 5.0:
              print(f'ERROR: Flakiness rate {flakiness_rate:.1f}% exceeds budget of 5%')
              sys.exit(1)

          if quarantine_rate > 2.0:
              print(f'ERROR: Quarantine rate {quarantine_rate:.1f}% exceeds budget of 2%')
              sys.exit(1)

          print('✅ Flakiness budget check passed')
          "

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');

            // Read flakiness report
            const report = `## Flakiness Budget Check

            **Status**: ✅ Passed
            **Flakiness Rate**: Within budget (≤5%)
            **Quarantine Rate**: Within budget (≤2%)

            ### Recommendations
            - Continue monitoring test stability
            - Address any flaky tests promptly
            - Maintain test isolation best practices`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });

  performance-regression-gate:
    runs-on: ubuntu-latest
    needs: test-impact-analysis
    if: always() && (needs.test-impact-analysis.outputs.impact-level == 'high' || contains(needs.test-impact-analysis.outputs.affected-services, 'performance'))

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-rerunfailures pytest-asyncio locust

      - name: Run performance tests
        run: |
          pytest tests/performance/ -v --tb=short

      - name: Check performance regression
        run: |
          python scripts/performance_regression_check.py

      - name: Upload performance artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: performance-results
          path: |
            performance-reports/
            locust-reports/

  security-suite:
    runs-on: ubuntu-latest
    needs: test-impact-analysis
    if: always() && contains(needs.test-impact-analysis.outputs.affected-services, 'security')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-rerunfailures pytest-asyncio

      - name: Run security tests
        run: |
          pytest tests/integration/security/ tests/adversarial/ -v --tb=short

      - name: Security gate check
        run: |
          # Any security test failure should block merge
          if [ $? -ne 0 ]; then
            echo "SECURITY TESTS FAILED - Merge blocked"
            exit 1
          fi
          echo "✅ Security tests passed"

  final-merge-gate:
    runs-on: ubuntu-latest
    needs:
      [
        test-impact-analysis,
        flakiness-budget-check,
        selective-testing,
        security-suite,
      ]
    if: always() && github.event_name == 'pull_request'

    steps:
      - name: Merge gate check
        run: |
          echo "## Merge Gate Status"
          echo "Checking all required conditions..."

          # Check if any critical jobs failed
          if [[ "${{ needs.flakiness-budget-check.result }}" != "success" ]]; then
            echo "❌ Flakiness budget check failed"
            exit 1
          fi

          if [[ "${{ needs.security-suite.result }}" == "failure" ]]; then
            echo "❌ Security tests failed"
            exit 1
          fi

          echo "✅ All merge gate conditions passed"
          echo "Merge is approved"

name: Evaluation Suite

on:
  schedule:
    - cron: '0 2 * * *'  # Run nightly at 2 AM UTC
  workflow_dispatch:
    inputs:
      tenant_id:
        description: 'Tenant ID for evaluation'
        required: true
        default: 'test-tenant'
      max_tasks:
        description: 'Maximum number of tasks'
        required: false
        default: '100'
      categories:
        description: 'Task categories (comma-separated)'
        required: false
        default: 'faq,order,tracking,lead'
      difficulties:
        description: 'Task difficulties (comma-separated)'
        required: false
        default: 'easy,medium,hard'
      tiers:
        description: 'Expected tiers (comma-separated)'
        required: false
        default: 'SLM_A,SLM_B,LLM_C'
  pull_request:
    paths:
      - 'eval/**'
      - 'apps/**'
      - 'services/**'
      - '.github/workflows/eval.yml'

env:
  PYTHON_VERSION: '3.11'
  REDIS_URL: 'redis://localhost:6379'
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

jobs:
  eval-nightly:
    if: github.event_name == 'schedule'
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    services:
      redis:
        image: redis:7
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r eval/requirements.txt
      
      - name: Run evaluation suite
        run: |
          python eval/run_evaluation.py \
            --tenant-id "nightly-eval" \
            --max-tasks 200 \
            --batch-size 20 \
            --threshold-pass-rate 0.85 \
            --threshold-average-score 0.75 \
            --categories faq order tracking lead \
            --difficulties easy medium hard \
            --tiers SLM_A SLM_B LLM_C \
            --output-file eval-results.json \
            --ci-mode
      
      - name: Upload evaluation results
        uses: actions/upload-artifact@v3
        with:
          name: eval-results-nightly
          path: eval-results.json
          retention-days: 30
      
      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('eval-results.json', 'utf8'));
            
            const comment = `## Evaluation Results
            
            **Status**: ${results.status}
            **Tasks**: ${results.task_count}
            **Duration**: ${results.duration_seconds.toFixed(2)}s
            **Passes Threshold**: ${results.passes_threshold ? '✅' : '❌'}
            
            ### Metrics
            - **Success Rate**: ${(results.metrics.success_rate * 100).toFixed(1)}%
            - **Pass Rate**: ${(results.metrics.pass_rate * 100).toFixed(1)}%
            - **Average Score**: ${results.metrics.average_score.toFixed(3)}
            - **Average Duration**: ${results.metrics.average_duration_ms.toFixed(0)}ms
            
            ### Score Distribution
            - **Excellent** (≥0.9): ${results.metrics.score_distribution.excellent}
            - **Good** (0.7-0.9): ${results.metrics.score_distribution.good}
            - **Fair** (0.5-0.7): ${results.metrics.score_distribution.fair}
            - **Poor** (<0.5): ${results.metrics.score_distribution.poor}
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
      
      - name: Fail if evaluation doesn't pass threshold
        if: steps.eval.outcome != 'success' || !results.passes_threshold
        run: |
          echo "Evaluation failed or didn't pass threshold"
          exit 1

  eval-pr:
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    services:
      redis:
        image: redis:7
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r eval/requirements.txt
      
      - name: Run focused evaluation
        id: eval
        run: |
          python eval/run_evaluation.py \
            --tenant-id "pr-eval" \
            --max-tasks 50 \
            --batch-size 10 \
            --threshold-pass-rate 0.8 \
            --threshold-average-score 0.7 \
            --categories faq order \
            --difficulties easy medium \
            --tiers SLM_A SLM_B \
            --output-file eval-results.json \
            --ci-mode
      
      - name: Upload evaluation results
        uses: actions/upload-artifact@v3
        with:
          name: eval-results-pr
          path: eval-results.json
          retention-days: 7
      
      - name: Comment PR with results
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('eval-results.json', 'utf8'));
            
            const status_emoji = results.passes_threshold ? '✅' : '❌';
            const status_text = results.passes_threshold ? 'PASSED' : 'FAILED';
            
            const comment = `## Evaluation Results ${status_emoji}
            
            **Status**: ${status_text}
            **Tasks**: ${results.task_count}
            **Duration**: ${results.duration_seconds.toFixed(2)}s
            
            ### Metrics
            - **Success Rate**: ${(results.metrics.success_rate * 100).toFixed(1)}%
            - **Pass Rate**: ${(results.metrics.pass_rate * 100).toFixed(1)}%
            - **Average Score**: ${results.metrics.average_score.toFixed(3)}
            - **Average Duration**: ${results.metrics.average_duration_ms.toFixed(0)}ms
            
            ### Score Distribution
            - **Excellent** (≥0.9): ${results.metrics.score_distribution.excellent}
            - **Good** (0.7-0.9): ${results.metrics.score_distribution.good}
            - **Fair** (0.5-0.7): ${results.metrics.score_distribution.fair}
            - **Poor** (<0.5): ${results.metrics.score_distribution.poor}
            
            ${!results.passes_threshold ? '⚠️ **This PR does not meet the evaluation threshold and may be blocked from merging.**' : ''}
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
      
      - name: Fail if evaluation doesn't pass threshold
        if: !results.passes_threshold
        run: |
          echo "Evaluation failed to pass threshold"
          exit 1

  eval-manual:
    if: github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    services:
      redis:
        image: redis:7
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r eval/requirements.txt
      
      - name: Run custom evaluation
        run: |
          python eval/run_evaluation.py \
            --tenant-id "${{ github.event.inputs.tenant_id }}" \
            --max-tasks ${{ github.event.inputs.max_tasks }} \
            --categories ${{ github.event.inputs.categories }} \
            --difficulties ${{ github.event.inputs.difficulties }} \
            --tiers ${{ github.event.inputs.tiers }} \
            --output-file eval-results.json \
            --ci-mode
      
      - name: Upload evaluation results
        uses: actions/upload-artifact@v3
        with:
          name: eval-results-manual
          path: eval-results.json
          retention-days: 30
      
      - name: Display results
        run: |
          echo "## Evaluation Results"
          cat eval-results.json | jq '.'